# Progress Log

Formato por entrada:
- **DATE/TIME**:
- **Paso**:
- **Qué se hizo**:
- **Decisiones**:
- **Riesgos**:
- **Qué queda**:

---

- **DATE/TIME**: 2026-02-27 00:00 UTC
- **Paso**: Paso 1 — creación de roadmap + contratos
- **Qué se hizo**:
  - Se creó roadmap de implementación en prompts incrementales (`docs/ml_roadmap_codex.md`).
  - Se formalizó contrato de arquitectura por capas y puertos (`docs/architecture_contract.md`).
  - Se definió quality gate de core con cobertura >=85% sin UI bloqueante (`docs/ci_quality_gate.md`).
  - Se revisaron docs/README y se añadieron estándares mínimos de ingeniería (`docs/standards.md`) con referencias desde README y TESTING.
- **Decisiones**:
  - Adoptar enfoque Strangler por pasos pequeños.
  - Tratar UI como capa no bloqueante de cobertura en esta fase.
  - Mantener cambios documentales mínimos, sin refactor masivo.
- **Riesgos**:
  - Cobertura actual de core probablemente por debajo del objetivo hasta ejecutar pasos siguientes.
  - Posibles imports cruzados históricos que requieran corrección gradual.
- **Qué queda**:
  - Implementar Prompt 1 del roadmap (automatizar gate en CI real + medición estable).

- **DATE/TIME**: 2026-02-27 00:45 UTC
- **Paso**: Paso 2 — gate + tests core verdes
- **Qué se hizo**:
  - Se ejecutó diagnóstico (`pytest -q` y `pytest -q --maxfail=1 -x`) y se aislaron causas raíz de fallos.
  - Se corrigieron contratos rotos entre capa application/domain/infrastructure en citas (campos/enum/fechas alineados).
  - Se corrigieron mapeos de repositorios de medicamentos/materiales para instanciar modelos de dominio con el nombre de campo canónico.
  - Se corrigió la búsqueda textual en queries de pacientes/médicos/personal (evitando condición AND espuria con teléfono normalizado).
  - Se ajustó test de pacientes para validar el comportamiento real y canónico de `num_historia` autogenerado.
  - Se creó `scripts/quality_gate.py` como comando único reproducible local/CI con gate bloqueante de core >=85% y exclusión de UI.
  - Se actualizó `docs/ci_quality_gate.md` para reflejar implementación real.
- **Decisiones**:
  - Se priorizó arreglo mínimo orientado a estabilidad de CI de core sin refactor masivo.
  - UI queda fuera del gate bloqueante (marker `ui` en pytest, excluido por diseño en el script).
  - No se añadieron herramientas nuevas de lint; solo ejecución condicional si la configuración ya existe.
- **Riesgos**:
  - El cálculo de cobertura usa trazado estándar de Python (no pytest-cov), por restricciones del entorno sin instalación de dependencias.
  - Persisten warnings de adaptador datetime de sqlite3 en Python 3.12 (no bloqueante para este paso).
- **Qué queda**:
  - Cuando haya acceso a dependencias de red/CI, evaluar migración de cálculo de cobertura a `pytest-cov` manteniendo el mismo contrato de core.

- **DATE/TIME**: 2026-02-27 22:05 UTC
- **Paso**: Paso 4: Pipeline extracción citas v1
- **Qué se hizo**:
  - Se definió el contrato de lectura `CitasReadPort` y el read-model `CitaReadModel` para desacoplar la extracción de la capa UI.
  - Se implementó el caso de uso `BuildCitasDataset` para construir filas tabulares con filtros por rango, mapeo tipado e invariantes (`duracion_min >= 0`, control de nulos en notas).
  - Se añadió el adaptador `SqliteCitasReadAdapter` en infraestructura, reutilizando repositorios existentes de citas/incidencias.
  - Se extendió `CitasRepository` con `list_in_range(...)` para lectura temporal canónica.
  - Se añadieron tests unitarios del builder con fakes y un test de contrato del adaptador sin SQLite real.
- **Decisiones**:
  - El puerto vive en `application/ports` porque el caso de uso de extracción pertenece a application y debe depender de abstracciones.
  - El dataset se modela con dataclass (`CitasDatasetRow`) para tipado fuerte y evolución segura hacia features ML.
  - Se reutiliza `IncidenciasRepository.search(cita_id=...)` para derivar `has_incidencias`, evitando duplicación SQL prematura en esta versión v1.
- **Riesgos**:
  - El adaptador actual consulta incidencias por cita (patrón N+1) y puede requerir optimización cuando el volumen crezca.
- **Qué queda**:
  - Añadir transforms de features (p. ej. franja horaria, día semana, lead time).
  - Definir persistencia/versionado de dataset (feature store ligero).
  - Preparar contratos para dataset de entrenamiento/validación.

- **DATE/TIME**: 2026-02-27 22:40 UTC
- **Paso**: Paso 5: Features citas v1 + quality report
- **Qué se hizo**:
  - Se creó el módulo puro de application `application/features/citas_features.py` con DTO canónico `CitasFeatureRow` y transformaciones deterministas desde `list[CitasDatasetRow]`.
  - Se implementó `build_citas_features(...)` con normalización de estado, buckets de duración/notas, señales temporales (`hora_inicio`, `dia_semana`, `is_weekend`) y flag `is_suspicious`.
  - Se implementó `validate_citas_features(...)` para invariantes de calidad mínimas y explícitas.
  - Se implementó `CitasFeatureQualityReport` + `compute_citas_quality_report(...)` con contadores agregados por estado y buckets.
  - Se añadieron tests unitarios dedicados en `tests/test_citas_features.py` para happy path, notas en cero, outliers, validación y reporte.
- **Decisiones**:
  - Outliers de duración (`duracion_min > 240`) no rompen pipeline: se marcan con `is_suspicious=True` y se contabilizan en el reporte.
  - Duración no positiva solo se permite para `estado_norm="cancelada"`; para otros estados la validación lanza error explícito.
  - `missing_count` del reporte se calcula como features con `estado_norm="desconocido"`.
  - `lead_time_min` se omite en v1 porque `CitasDatasetRow` actual no expone `creada_en/reservada_en`.
- **Riesgos**:
  - La normalización de estados cubre alias comunes, pero pueden aparecer variantes nuevas que convenga mapear en una tabla de vocabulario de dominio.
- **Qué queda**:
  - Feature store/versionado de datasets y features.
  - Baseline de entrenamiento/evaluación con split reproducible.
  - Contrato de scoring online/offline y monitoreo de deriva de datos/features.

- **DATE/TIME**: 2026-02-27 23:10 UTC
- **Paso**: Paso 6: Feature Store offline v1
- **Qué se hizo**:
  - Se definió el contrato `FeatureStorePort` en application (contract-first) con operaciones `save`, `load` y `list_versions`.
  - Se implementó `LocalJsonFeatureStore` en infraestructura con persistencia local en `data/feature_store/<dataset>/<version>.json`, creación automática de carpetas y errores explícitos para dataset/versión inexistentes.
  - Se añadió `FeatureStoreService` en application para orquestar el dataset lógico `citas_features`, generar versión timestamp segura para filename y delegar la persistencia/carga al port.
  - Se incorporó test suite dedicada `tests/test_feature_store.py` cubriendo roundtrip, listado de versiones, errores explícitos, no sobreescritura entre versiones y serialización determinista.
- **Decisiones**:
  - Se eligió JSON local frente a SQLite en v1 para minimizar complejidad operativa, facilitar inspección humana y mantener cero dependencia externa.
  - Se fijó serialización determinista (`sort_keys=True`) para asegurar reproducibilidad binaria del artefacto al guardar el mismo contenido.
  - Se mantuvo el servicio de aplicación liviano y sin lógica de infraestructura para respetar Clean Architecture.
- **Riesgos**:
  - JSON completo por versión no escala bien para datasets grandes; podría requerir compresión/particionado.
  - No hay locking ni control de concurrencia en escrituras simultáneas.
  - La validación del payload cargado es mínima (solo tipo lista) y puede ampliarse con esquemas versionados.
- **Qué queda**:
  - Definir online store y estrategia híbrida offline/online.
  - Incorporar locking atómico y manejo robusto de concurrencia.
  - Añadir metadatos de lineage, checksum y gobernanza de versiones.

- **DATE/TIME**: 2026-02-28 00:05 UTC
- **Paso**: Paso 7: Baseline predictor + scoring use case
- **Qué se hizo**:
  - Se definió el contrato de inferencia `PredictorPort` en application con tipos públicos `PredictorInput` y `PredictionResult`.
  - Se implementó `BaselineCitasPredictor` determinista en application (`ml/`) con reglas explicables, score clamped en `[0,1]`, labels (`low/medium/high`) y `reasons` trazables.
  - Se implementó el caso de uso `ScoreCitas` con request/response tipados, carga desde `FeatureStoreService`, soporte de `limit` y mapeo a `ScoredCita`.
  - Se añadieron errores explícitos de dominio de aplicación (`ScoringDatasetNotFoundError`, `ScoringValidationError`) para separar fallos de acceso a datos y validación.
  - Se añadieron tests unitarios dedicados para predictor y use case usando fakes simples y sin dependencias externas.
- **Decisiones**:
  - El baseline se mantuvo 100% determinista y sin estado para permitir reproducibilidad, trazabilidad y debugging temprano sin pipeline de entrenamiento.
  - Se ubicó el predictor en `application` (no infraestructura) porque encapsula reglas puras de negocio/heurística.
  - Se priorizó contrato estable (`PredictorPort`) para poder reemplazar baseline por un modelo real sin romper casos de uso.
- **Riesgos**:
  - Las reglas heurísticas no sustituyen evaluación estadística real; pueden sesgar decisiones en distribución cambiante.
  - La deserialización actual asume schema de features estable; cambios de contrato requerirán versionado explícito.
- **Qué queda**:
  - Integrar modelo entrenable real (offline + evaluación), con métricas y calibración.
  - Definir pipeline de entrenamiento y registro de artefactos/versiones de modelo.
  - Añadir monitoreo de drift de datos/features y validaciones de scoring online.
