# Progress Log

Formato por entrada:
- **DATE/TIME**:
- **Paso**:
- **Qué se hizo**:
- **Decisiones**:
- **Riesgos**:
- **Qué queda**:

---

- **DATE/TIME**: 2026-02-27 00:00 UTC
- **Paso**: Paso 1 — creación de roadmap + contratos
- **Qué se hizo**:
  - Se creó roadmap de implementación en prompts incrementales (`docs/ml_roadmap_codex.md`).
  - Se formalizó contrato de arquitectura por capas y puertos (`docs/architecture_contract.md`).
  - Se definió quality gate de core con cobertura >=85% sin UI bloqueante (`docs/ci_quality_gate.md`).
  - Se revisaron docs/README y se añadieron estándares mínimos de ingeniería (`docs/standards.md`) con referencias desde README y TESTING.
- **Decisiones**:
  - Adoptar enfoque Strangler por pasos pequeños.
  - Tratar UI como capa no bloqueante de cobertura en esta fase.
  - Mantener cambios documentales mínimos, sin refactor masivo.
- **Riesgos**:
  - Cobertura actual de core probablemente por debajo del objetivo hasta ejecutar pasos siguientes.
  - Posibles imports cruzados históricos que requieran corrección gradual.
- **Qué queda**:
  - Implementar Prompt 1 del roadmap (automatizar gate en CI real + medición estable).

- **DATE/TIME**: 2026-02-27 00:45 UTC
- **Paso**: Paso 2 — gate + tests core verdes
- **Qué se hizo**:
  - Se ejecutó diagnóstico (`pytest -q` y `pytest -q --maxfail=1 -x`) y se aislaron causas raíz de fallos.
  - Se corrigieron contratos rotos entre capa application/domain/infrastructure en citas (campos/enum/fechas alineados).
  - Se corrigieron mapeos de repositorios de medicamentos/materiales para instanciar modelos de dominio con el nombre de campo canónico.
  - Se corrigió la búsqueda textual en queries de pacientes/médicos/personal (evitando condición AND espuria con teléfono normalizado).
  - Se ajustó test de pacientes para validar el comportamiento real y canónico de `num_historia` autogenerado.
  - Se creó `scripts/quality_gate.py` como comando único reproducible local/CI con gate bloqueante de core >=85% y exclusión de UI.
  - Se actualizó `docs/ci_quality_gate.md` para reflejar implementación real.
- **Decisiones**:
  - Se priorizó arreglo mínimo orientado a estabilidad de CI de core sin refactor masivo.
  - UI queda fuera del gate bloqueante (marker `ui` en pytest, excluido por diseño en el script).
  - No se añadieron herramientas nuevas de lint; solo ejecución condicional si la configuración ya existe.
- **Riesgos**:
  - El cálculo de cobertura usa trazado estándar de Python (no pytest-cov), por restricciones del entorno sin instalación de dependencias.
  - Persisten warnings de adaptador datetime de sqlite3 en Python 3.12 (no bloqueante para este paso).
- **Qué queda**:
  - Cuando haya acceso a dependencias de red/CI, evaluar migración de cálculo de cobertura a `pytest-cov` manteniendo el mismo contrato de core.

- **DATE/TIME**: 2026-02-27 22:05 UTC
- **Paso**: Paso 4: Pipeline extracción citas v1
- **Qué se hizo**:
  - Se definió el contrato de lectura `CitasReadPort` y el read-model `CitaReadModel` para desacoplar la extracción de la capa UI.
  - Se implementó el caso de uso `BuildCitasDataset` para construir filas tabulares con filtros por rango, mapeo tipado e invariantes (`duracion_min >= 0`, control de nulos en notas).
  - Se añadió el adaptador `SqliteCitasReadAdapter` en infraestructura, reutilizando repositorios existentes de citas/incidencias.
  - Se extendió `CitasRepository` con `list_in_range(...)` para lectura temporal canónica.
  - Se añadieron tests unitarios del builder con fakes y un test de contrato del adaptador sin SQLite real.
- **Decisiones**:
  - El puerto vive en `application/ports` porque el caso de uso de extracción pertenece a application y debe depender de abstracciones.
  - El dataset se modela con dataclass (`CitasDatasetRow`) para tipado fuerte y evolución segura hacia features ML.
  - Se reutiliza `IncidenciasRepository.search(cita_id=...)` para derivar `has_incidencias`, evitando duplicación SQL prematura en esta versión v1.
- **Riesgos**:
  - El adaptador actual consulta incidencias por cita (patrón N+1) y puede requerir optimización cuando el volumen crezca.
- **Qué queda**:
  - Añadir transforms de features (p. ej. franja horaria, día semana, lead time).
  - Definir persistencia/versionado de dataset (feature store ligero).
  - Preparar contratos para dataset de entrenamiento/validación.

- **DATE/TIME**: 2026-02-27 22:40 UTC
- **Paso**: Paso 5: Features citas v1 + quality report
- **Qué se hizo**:
  - Se creó el módulo puro de application `application/features/citas_features.py` con DTO canónico `CitasFeatureRow` y transformaciones deterministas desde `list[CitasDatasetRow]`.
  - Se implementó `build_citas_features(...)` con normalización de estado, buckets de duración/notas, señales temporales (`hora_inicio`, `dia_semana`, `is_weekend`) y flag `is_suspicious`.
  - Se implementó `validate_citas_features(...)` para invariantes de calidad mínimas y explícitas.
  - Se implementó `CitasFeatureQualityReport` + `compute_citas_quality_report(...)` con contadores agregados por estado y buckets.
  - Se añadieron tests unitarios dedicados en `tests/test_citas_features.py` para happy path, notas en cero, outliers, validación y reporte.
- **Decisiones**:
  - Outliers de duración (`duracion_min > 240`) no rompen pipeline: se marcan con `is_suspicious=True` y se contabilizan en el reporte.
  - Duración no positiva solo se permite para `estado_norm="cancelada"`; para otros estados la validación lanza error explícito.
  - `missing_count` del reporte se calcula como features con `estado_norm="desconocido"`.
  - `lead_time_min` se omite en v1 porque `CitasDatasetRow` actual no expone `creada_en/reservada_en`.
- **Riesgos**:
  - La normalización de estados cubre alias comunes, pero pueden aparecer variantes nuevas que convenga mapear en una tabla de vocabulario de dominio.
- **Qué queda**:
  - Feature store/versionado de datasets y features.
  - Baseline de entrenamiento/evaluación con split reproducible.
  - Contrato de scoring online/offline y monitoreo de deriva de datos/features.

- **DATE/TIME**: 2026-02-27 23:10 UTC
- **Paso**: Paso 6: Feature Store offline v1
- **Qué se hizo**:
  - Se definió el contrato `FeatureStorePort` en application (contract-first) con operaciones `save`, `load` y `list_versions`.
  - Se implementó `LocalJsonFeatureStore` en infraestructura con persistencia local en `data/feature_store/<dataset>/<version>.json`, creación automática de carpetas y errores explícitos para dataset/versión inexistentes.
  - Se añadió `FeatureStoreService` en application para orquestar el dataset lógico `citas_features`, generar versión timestamp segura para filename y delegar la persistencia/carga al port.
  - Se incorporó test suite dedicada `tests/test_feature_store.py` cubriendo roundtrip, listado de versiones, errores explícitos, no sobreescritura entre versiones y serialización determinista.
- **Decisiones**:
  - Se eligió JSON local frente a SQLite en v1 para minimizar complejidad operativa, facilitar inspección humana y mantener cero dependencia externa.
  - Se fijó serialización determinista (`sort_keys=True`) para asegurar reproducibilidad binaria del artefacto al guardar el mismo contenido.
  - Se mantuvo el servicio de aplicación liviano y sin lógica de infraestructura para respetar Clean Architecture.
- **Riesgos**:
  - JSON completo por versión no escala bien para datasets grandes; podría requerir compresión/particionado.
  - No hay locking ni control de concurrencia en escrituras simultáneas.
  - La validación del payload cargado es mínima (solo tipo lista) y puede ampliarse con esquemas versionados.
- **Qué queda**:
  - Definir online store y estrategia híbrida offline/online.
  - Incorporar locking atómico y manejo robusto de concurrencia.
  - Añadir metadatos de lineage, checksum y gobernanza de versiones.

- **DATE/TIME**: 2026-02-28 00:05 UTC
- **Paso**: Paso 7: Baseline predictor + scoring use case
- **Qué se hizo**:
  - Se definió el contrato de inferencia `PredictorPort` en application con tipos públicos `PredictorInput` y `PredictionResult`.
  - Se implementó `BaselineCitasPredictor` determinista en application (`ml/`) con reglas explicables, score clamped en `[0,1]`, labels (`low/medium/high`) y `reasons` trazables.
  - Se implementó el caso de uso `ScoreCitas` con request/response tipados, carga desde `FeatureStoreService`, soporte de `limit` y mapeo a `ScoredCita`.
  - Se añadieron errores explícitos de dominio de aplicación (`ScoringDatasetNotFoundError`, `ScoringValidationError`) para separar fallos de acceso a datos y validación.
  - Se añadieron tests unitarios dedicados para predictor y use case usando fakes simples y sin dependencias externas.
- **Decisiones**:
  - El baseline se mantuvo 100% determinista y sin estado para permitir reproducibilidad, trazabilidad y debugging temprano sin pipeline de entrenamiento.
  - Se ubicó el predictor en `application` (no infraestructura) porque encapsula reglas puras de negocio/heurística.
  - Se priorizó contrato estable (`PredictorPort`) para poder reemplazar baseline por un modelo real sin romper casos de uso.
- **Riesgos**:
  - Las reglas heurísticas no sustituyen evaluación estadística real; pueden sesgar decisiones en distribución cambiante.
  - La deserialización actual asume schema de features estable; cambios de contrato requerirán versionado explícito.
- **Qué queda**:
  - Integrar modelo entrenable real (offline + evaluación), con métricas y calibración.
  - Definir pipeline de entrenamiento y registro de artefactos/versiones de modelo.
  - Añadir monitoreo de drift de datos/features y validaciones de scoring online.

- **DATE/TIME**: 2026-02-28 00:40 UTC
- **Paso**: Paso 8: Lineage + metadata + schema + hashes
- **Qué se hizo**:
  - Se creó el módulo de artefactos ML en application con modelos `FeatureSchemaField`, `FeatureSchema`, `FeatureArtifactMetadata` y helpers puros para hashing/canonicalización.
  - Se extendió el puerto `FeatureStorePort` con `save_with_metadata(...)` y `load_metadata(...)` manteniendo `save/load/list_versions` para compatibilidad.
  - Se evolucionó `LocalJsonFeatureStore` para persistir por versión tres artefactos (`.json`, `.metadata.json`, `.schema.json`) y para exponer errores explícitos cuando faltan metadata o schema.
  - Se añadió `FeatureStoreService.save_citas_features_with_artifacts(...)` para construir schema/hashes/metadata+quality report de `citas_features` y persistirlos de forma reproducible.
  - Se integró validación de metadata en `ScoreCitas`: cuando hay metadata valida `row_count` y `content_hash`; si no existe metadata continúa por compatibilidad agregando reason informativa.
  - Se añadió test suite `tests/test_feature_store_artifacts.py` con casos de creación de artefactos, hashes deterministas, estabilidad de schema y validación en scoring con metadata inconsistente.
- **Decisiones**:
  - Compatibilidad hacia atrás: scoring no falla si falta metadata en versiones antiguas; solo agrega reason `metadata no disponible para esta versión`.
  - `schema_hash` y `content_hash` se calculan sobre JSON canónico (`sort_keys=True`, `separators` compactos) para reproducibilidad binaria.
  - El schema persistido en infraestructura se deriva de las filas serializadas y el schema de aplicación se deriva del dataclass de features para contrato estable de `citas_features`.
- **Riesgos**:
  - No hay locking transaccional ni escritura atómica multiarchivo entre rows/schema/metadata.
  - Falta firma criptográfica de artefactos y registro global de datasets/versiones.
- **Qué queda**:
  - Añadir lock/atomic writes y estrategia anti-corrupción de artefactos parcialmente escritos.
  - Incorporar firma de artefactos y dataset registry centralizado con políticas de retención.
  - Definir validación de compatibilidad de `schema_version` durante scoring y entrenamiento.

- **DATE/TIME**: 2026-02-28 01:25 UTC
- **Paso**: Paso 9: Train + evaluate + model store offline
- **Qué se hizo**:
  - Se agregó `derive_target_from_feature(...)` como etiqueta proxy determinista (`1` si `has_incidencias` o `is_suspicious`, si no `0`) para habilitar pipeline end-to-end reproducible sin dependencias externas.
  - Se implementó modelo entrenable determinista tipo Naive Bayes discreto en application (`train/predict_one/predict_batch`) con suavizado de Laplace y payload serializable.
  - Se incorporó módulo de evaluación offline (`EvalMetrics`) con accuracy, precision, recall y matriz de confusión (`tp/fp/tn/fn`) usando threshold fijo `score>=0.5`.
  - Se definió el puerto `ModelStorePort` y su implementación `LocalJsonModelStore` para versionado offline en `base/models/<model>/<version>.*.json`.
  - Se creó caso de uso `TrainCitasModel` para: cargar features versionadas + metadata, validar `schema_hash`, entrenar, evaluar sobre el dataset actual, y registrar payload+metadata+métricas del modelo.
  - Se extendió `ScoreCitas` para seleccionar predictor por request (`baseline|trained`), cargar modelo entrenado por versión, validar compatibilidad de `schema_hash` y anexar reason `trained_model:<name>@<version>`.
  - Se añadieron tests core de entrenamiento, model store y scoring con modelo entrenado (incluyendo mismatch de schema).
- **Decisiones**:
  - Se eligió Naive Bayes discreto por ser corto, determinista, explicable y sin optimización numérica compleja.
  - Se conservó `baseline` como default para compatibilidad total hacia atrás.
  - La etiqueta se documenta explícitamente como **proxy label** (no ground-truth clínica).
- **Riesgos**:
  - La evaluación se ejecuta sobre el mismo dataset de entrenamiento (optimista y no generalizable).
  - El target proxy introduce leakage intencional en esta fase inicial; útil para validar plumbing, no para performance real.
  - Persistencia del model store es local JSON sin locking/atomicidad multiarchivo.
- **Qué queda**:
  - Incorporar split reproducible train/validation/holdout y/o CV.
  - Diseñar etiquetado real de negocio (ground truth) y calibración de scores.
  - Añadir validaciones de drift y políticas de promoción de modelos.

- **DATE/TIME**: 2026-02-28 02:10 UTC
- **Paso**: Paso 10: Evaluación holdout temporal + backtesting simple
- **Qué se hizo**:
  - Se añadió `application/ml/splitting.py` con `TemporalSplitConfig`, `temporal_train_test_split(...)`, error explícito `TemporalSplitNotEnoughDataError` y `temporal_folds(...)` walk-forward determinista.
  - Se evolucionó `CitasFeatureRow` incorporando `inicio_ts` (epoch int) para habilitar split temporal serializable sin romper persistencia JSON del feature store.
  - Se actualizó `TrainCitasModel` para cargar features, aplicar split temporal determinista (80/20, `min_train=20`), entrenar solo con train y evaluar por separado en train/test.
  - Se cambió metadata del modelo para incluir `split_config`, `train_metrics`, `test_metrics` y `test_row_count`; además el response del use case ahora expone ambas métricas.
  - Se agregó adaptación de error de split insuficiente a `TrainCitasModelNotEnoughDataError` para cortar entrenamiento de forma explícita.
  - Se añadieron tests core: `tests/test_temporal_split.py` y extensión de `tests/test_ml_training.py` para verificar split determinista, error por datos insuficientes y persistencia de métricas train/test.
- **Decisiones**:
  - Campo temporal elegido: `inicio_ts` en `CitasFeatureRow` para evitar serialización de `datetime` en artefactos JSON.
  - Configuración base de split: `test_ratio=0.2`, `min_train=20`, orden ascendente por tiempo.
  - Backtesting implementado como helper opcional en módulo de split con ventanas fijas 60/20, 80/20 y 90/10.
- **Limitaciones**:
  - `temporal_folds(...)` queda disponible pero no se integra aún en metadata de entrenamiento para mantener cambio mínimo del caso de uso.
  - El target sigue siendo proxy label derivada de features, útil para plumbing/CI pero no equivalente a ground-truth clínico.

- **DATE/TIME**: 2026-02-28 03:05 UTC
- **Paso**: Paso 11: Calibración de threshold + drift report
- **Qué se hizo**:
  - Se añadió calibración de threshold en `application/ml/calibration.py` con políticas `min_recall`, `min_precision` y `f1_max`, además de cálculo puro de métricas por threshold.
  - Se integró la calibración en `TrainCitasModel`: scoring en holdout temporal, selección de threshold calibrado y persistencia de `calibrated_threshold`, `calibration_policy` y `test_metrics_at_calibrated_threshold` en metadata del modelo.
  - Se actualizó `ScoreCitas` para predictor entrenado: aplica `calibrated_threshold` de metadata para etiqueta binaria (`risk`/`no_risk`) y agrega reason `threshold:<thr>`; mantiene fallback a `0.5` por compatibilidad.
  - Se añadió `application/ml/drift.py` con `DriftReport`, distribución categórica, PSI y cálculo de drift sobre features discretas clave.
  - Se añadió el caso de uso `DriftCitasFeatures` para comparar dos versiones de features vía `FeatureStoreService` y devolver `DriftReport`.
  - Se agregaron tests core dedicados para calibración, integración train+scoring calibrado y drift.
- **Decisiones**:
  - Policy por defecto de calibración: `objective=min_recall`, `value=0.80`, `threshold` fallback de `0.5`.
  - Umbral de alerta PSI: `0.2` para `overall_flag=True` cuando al menos una feature supera ese valor.
  - En objetivos `min_*`, si no hay threshold que cumpla target se devuelve el threshold más cercano por métrica objetivo.
- **Limitaciones**:
  - La calibración usa el test set temporal del mismo pipeline offline y etiqueta proxy; no sustituye validación clínica con ground-truth.
  - El reporte de drift actual cubre solo features categóricas discretas y no persiste artefacto JSON en store (solo retorno en use case).
- **Qué queda**:
  - Incorporar persistencia opcional del drift report como artefacto versionado y alarmas automáticas de CI/CD.
  - Evaluar thresholds dinámicos por segmento operativo (especialidad/sede) cuando existan labels reales.

- **DATE/TIME**: 2026-02-27 00:00 UTC
- **Paso**: Paso 12: CLI ML operativa
- **Qué se hizo**:
  - Se creó `scripts/ml_cli.py` con `argparse` (stdlib) y subcomandos `build-features`, `train`, `score` y `drift`, manteniendo el script como capa de orquestación sin lógica de negocio de dominio.
  - `build-features` ejecuta pipeline completo (`BuildCitasDataset` -> `build_citas_features` -> `compute_citas_quality_report` -> `FeatureStoreService.save_citas_features_with_artifacts`) y reporta `saved_version`, `row_count`, `suspicious_count`.
  - Se incorporó wiring de infraestructura para modo real vía SQLite (`bootstrap_database` + `SqliteCitasReadAdapter`) y fallback explícito `--demo-fake` con dataset determinista sintético (40 citas).
  - `train` orquesta `TrainCitasModel` con `LocalJsonFeatureStore` + `LocalJsonModelStore`; imprime versión y métricas principales con threshold calibrado.
  - `score` orquesta `ScoreCitas` baseline/trained, imprime tabla estable (`cita_id | score | label | reasons`) y resumen agregado por labels.
  - `drift` orquesta `DriftCitasFeatures` e imprime `psi_by_feature` + `overall_flag`.
  - Se añadió `tests/test_ml_cli_smoke.py` para smoke determinista llamando `main()` directamente (sin subprocess) sobre build/train/score/drift en `tmp_path`.
- **Decisiones de wiring**:
  - Se mantiene la CLI aislada en `scripts/` y solo instancia adaptadores concretos (`LocalJsonFeatureStore`, `LocalJsonModelStore`, `SqliteCitasReadAdapter`).
  - Se validó `model-name` contra el contrato actual (`citas_nb_v1`) para evitar rutas ambiguas mientras el use case de entrenamiento mantiene nombre fijo.
- **Modo demo-fake**:
  - Se añadió `--demo-fake` como fallback seguro y reproducible cuando no se use/disponga SQLite real.
  - Se añadió `--demo-profile baseline|shifted` para generar dos distribuciones distintas y habilitar demos de drift en segundos.

- **DATE/TIME**: 2026-02-28 03:45 UTC
- **Paso**: Paso 13: Capa de exportación CSV estable + CLI `export`
- **Qué se hizo**:
  - Se añadió `clinicdesk/app/application/usecases/export_csv.py` con casos de uso de exportación determinista (`ExportFeaturesCSV`, `ExportModelMetricsCSV`, `ExportScoringCSV`, `ExportDriftCSV`) usando solo stdlib (`csv`, `pathlib`).
  - Se definieron contratos de columnas estables y orden fijo para `features_export.csv`, `model_metrics_export.csv`, `scoring_export.csv` y `drift_export.csv`.
  - Se integró la CLI con comando `export` y subcomandos `features`, `metrics`, `scoring`, `drift`, manteniendo scripts como orquestación sin lógica de negocio.
  - Se añadió smoke de CLI y pruebas unitarias de export en `tests/test_csv_exports.py` usando `tmp_path` (sin tocar filesystem real).
  - Se documentó integración Power BI en `docs/ci_quality_gate.md` con comandos listos para copy/paste.
- **Decisiones**:
  - CSV con serialización determinista (`float` con 6 decimales, `bool` como `0/1`) para estabilidad de ingestion.
  - Para `export metrics`, la CLI adapta metadata del model store a DTO de export sin recalcular métricas.
- **Limitaciones**:
  - `dataset_version` en `export metrics` se recibe por CLI; no se infiere automáticamente desde metadata para mantener contrato explícito del comando.

- **DATE/TIME**: 2026-02-28 05:10 UTC
- **Paso**: Paso 14: Demo dataset seed reproducible (médicos/pacientes/citas)
- **Qué se hizo**:
  - Se creó módulo puro `application/demo_data` con DTOs desacoplados de SQLite y generadores deterministas para médicos, pacientes, personal, citas e incidencias.
  - Se añadió seeder de infraestructura `infrastructure/sqlite/demo_data_seeder.py` para persistir entidades con repos canónicos respetando FK y creando salas por defecto si faltan.
  - Se añadió caso de uso `SeedDemoData` con request/response tipadas para orquestar generación + persistencia.
  - Se extendió `scripts/ml_cli.py` con comando `seed-demo` y parámetros de configuración (`seed`, volúmenes, rango de fechas, incidencia y `--sqlite-path`).
  - Se añadieron tests puros del generador y test de integración SQLite del seeder.
  - Se documentó el flujo end-to-end para demos (seed → build-features → train → export → Power BI).
- **Decisiones**:
  - Mantener el script CLI como orquestador, delegando reglas de negocio de generación al módulo puro de application.
  - Usar `random.Random(seed + offset)` por entidad para preservar reproducibilidad y permitir crecimiento modular.
  - Incluir distribución realista base: mayoría laborables, buckets de duración y outliers controlados.
- **Riesgos**:
  - El comando `seed-demo` inserta incrementalmente (no limpia tablas); ejecuciones repetidas sobre la misma BD pueden acumular datos demo.
- **Qué queda**:
  - Evaluar comando opcional de limpieza/reset para escenarios de demo repetibles en la misma base persistente.

- **DATE/TIME**: 2026-02-28 06:10 UTC
- **Paso**: Paso 15: UI Demo & ML
- **Qué se hizo**:
  - Se creó `DemoMLFacade` en application para orquestar seed, listados demo, build-features, train, score, drift y export CSV sin exponer detalles de infraestructura a la UI.
  - Se añadieron read models tipados para tablas de médicos, pacientes, citas e incidencias consumidas por la pantalla Demo.
  - Se incorporó gateway SQLite dedicado (`SqliteDemoMLReadGateway`) para consultas de lectura de demo, inyectado desde `AppContainer`.
  - Se añadió la página UI `Demo & ML` con panel de seed, tabs de exploración con búsqueda, acciones ML y área de resultados/logs.
  - Las operaciones potencialmente largas se ejecutan en background con `QThread` para evitar congelar la ventana principal.
  - Se añadieron tests puros de facade con fakes para seed, score y export.
- **Decisiones**:
  - Se mantuvo el facade deliberadamente thin: orquesta use cases existentes y solo adapta output a contratos de UI.
  - Export en UI reutiliza respuestas en memoria de train/score/drift para evitar acoplar pantalla a stores concretos.
- **Limitaciones**:
  - La UI de escritorio no cuenta con test automatizado visual; se cubrió core/facade por tests de dominio/application.

- **DATE/TIME**: 2026-02-28 07:10 UTC
- **Paso**: Paso 16: One-click demo runner + progress/cancel
- **Qué se hizo**:
  - Se añadió `DemoRunService` en application para orquestar el flujo completo `seed -> build_features -> train -> score -> drift -> export` con contratos explícitos (`DemoRunConfig`, `DemoRunStepResult`, `DemoRunResult`) y `CancelToken` thread-safe.
  - El servicio reporta progreso por pasos, registra resultado detallado por etapa y entrega comandos CLI equivalentes para reproducibilidad.
  - Se incorporó `Run Full Demo` en la UI Demo & ML con barra de progreso, botón `Cancel`, resumen final, rutas de export y lista copiable de comandos CLI.
  - Se persistieron en `QSettings` los valores `last_dataset_version`, `last_model_version`, `last_export_dir` y `prev_dataset_version` para ejecutar drift incremental entre corridas.
  - Se agregaron tests core puros en `tests/test_demo_run_service.py` con `FakeDemoMLFacade` validando orden de pasos, progresión monotónica, cancelación, comandos CLI y 4 CSV de export.
- **Decisiones**:
  - La orquestación vive en `application/services` para mantener la UI sin lógica de negocio.
  - Drift usa `prev_dataset_version` de settings cuando existe; en caso contrario usa self-to para que la demo nunca falle por configuración inicial.
- **Limitaciones**:
  - La UI de escritorio se valida manualmente; no hay suite visual automatizada para PySide6.

- **DATE/TIME**: 2026-02-28 04:40 UTC
- **Paso**: Paso 13: Logging robusto (operational + soft/fatal crash), cero prints
- **Qué se hizo**:
  - Se implementó bootstrap central de logging en `clinicdesk/app/bootstrap_logging.py` con contexto `run_id/user`, salida consistente a consola y rotación de archivos (`app.log`, `crash_soft.log`, `crash_fatal.log`).
  - Se añadió `clinicdesk/app/crash_handler.py` para instalar hook global de excepciones (`sys.excepthook` y `threading.excepthook`) enviando tracebacks a fatal crash log.
  - Se agregó helper `log_soft_exception(...)` para registrar errores esperables como soft crash + operacional.
  - Se integró logging en `scripts/ml_cli.py`, `seed_demo_data.py`, `clinicdesk/app/main.py`, y `clinicdesk/tools/test_launcher.py` eliminando `print`.
  - Se añadió `LogBufferHandler` in-memory para UI (`clinicdesk/app/ui/log_buffer_handler.py`) como réplica opcional para logs en pantalla.
  - Se actualizó `scripts/quality_gate.py` para detectar y bloquear `print` fuera de allowlist.
  - Se añadieron tests smoke de logging/crash (`tests/test_logging_smoke.py`).
- **Decisiones**:
  - Formato estructurado configurable (`json=True/False`) con campos obligatorios de trazabilidad para observabilidad end-to-end.
  - Separación explícita de crashes esperables (soft) vs terminales (fatal) para operación y soporte.
- **Riesgos**:
  - Algunos módulos legacy siguen sin emitir logs de dominio ricos; la base queda preparada para extender instrumentación progresiva.
- **Qué queda**:
  - Extender correlación con `request_id` por interacción UI/servicio cuando exista capa de transporte explícita.

- **DATE/TIME**: 2026-02-28 06:20 UTC
- **Paso**: Fix seed-demo wiring SQLite + error SQL dispensaciones + observabilidad de progreso
- **Qué se hizo**:
  - Se auditó wiring de arranque y se confirmó que app/CLI usan `bootstrap_database`, unificando por defecto la BD en `./data/clinicdesk.db` y permitiendo override por `CLINICDESK_DB_PATH` o `--sqlite-path`.
  - Se corrigió `DispensacionesQueries.list` para derivar `incidencia` desde tabla `incidencias` (EXISTS por `dispensacion_id`) en lugar de leer columna inexistente `d.incidencia`.
  - Se añadió progreso estructurado por fases y lotes en seed-demo (generación, persistencia por batch, tiempos por fase y total).
  - Se mejoró persistencia de seed masivo con commits por lote en citas/incidencias para evitar sensación de cuelgue.
  - Se añadieron tests: wiring seed->query real en mismo sqlite path, cobertura de `DispensacionesQueries` con schema real sin columna legacy, y verificación de mensajes de progreso en logs.
- **Decisiones**:
  - Cambio mínimo sin refactor masivo: se mantuvieron repositorios existentes para entidades maestras y se optimizó en lote solo el camino caliente (citas/incidencias).
  - Se priorizó compatibilidad con arquitectura existente (seed en use case + infraestructura SQLite).
- **Riesgos**:
  - Persistencia de médicos/pacientes/personal sigue insertando por entidad (coste bajo relativo).
  - Existen componentes legacy que aún asumen columnas históricas en dispensaciones fuera del alcance de este ajuste.
- **Qué queda**:
  - Evaluar migración gradual de paths legacy `*.sqlite` en scripts/docs secundarios para eliminar ambigüedad histórica.

- **DATE/TIME**: 2026-02-28 09:05 UTC
- **Paso**: Paso 18: seed turbo + ETA + reset seguro
- **Qué se hizo**:
  - Se añadió `sqlite_seed_turbo(connection)` para activar PRAGMAs de seed (`journal_mode=WAL`, `synchronous=NORMAL`, `temp_store=MEMORY`, `cache_size=-20000`, `foreign_keys=ON`) y restaurar al salir los parámetros restaurables (`synchronous`, `temp_store`, `cache_size`).
  - Se mejoró el camino caliente de persistencia masiva con logs estructurados `seed_progress` por lote, incluyendo `phase`, `batch_index`, `batch_total`, `done`, `total`, `elapsed_s`, `rate` y `eta_s`.
  - Se implementó reset seguro de base demo con `UnsafeDatabaseResetError`, validación de ruta segura y recreación de schema tras borrado.
  - `scripts/ml_cli.py seed-demo` ahora soporta `--turbo/--no-turbo` y `--reset/--no-reset`; por defecto `reset` se activa solo en rutas seguras de demo.
  - Se alineó `seed_demo_data.py` para delegar turbo/reset al comando `seed-demo` sin lógica paralela de borrado.
  - Se agregaron tests de no-regresión para turbo pragmas, seguridad de reset y logs de progreso con ETA.
- **Decisiones**:
  - Se priorizó cambio mínimo sin refactor masivo: el control de turbo/reset vive en infraestructura y el orquestador CLI.
  - Se usa tasa global `done/elapsed` para ETA estable y determinista (1 log por lote).
- **Riesgos**:
  - `journal_mode` puede permanecer en WAL tras seed (comportamiento documentado y aceptable para uso normal en SQLite desktop).
- **Qué queda**:
  - Evaluar si conviene parametrizar `cache_size` turbo por volumen de dataset o perfil de máquina.

- **DATE/TIME**: 2026-02-28 10:25 UTC
- **Paso**: Fix path único SQLite seed/app + trazabilidad db_path_resolved/db_opened
- **Qué se hizo**:
  - Se centralizó la resolución de ruta SQLite en `resolve_db_path()` dentro de `clinicdesk/app/bootstrap.py` con precedencia `--sqlite-path` > `CLINICDESK_DB_PATH` > default oficial `./data/clinicdesk.db`.
  - Se instrumentó logging estructurado en bootstrap para registrar `db_path_resolved path=<...> source=<arg|env|default>` al resolver y `db_opened path=<...>` al abrir conexión.
  - `bootstrap_database()` ahora utiliza siempre `resolve_db_path()`, garantizando trazabilidad y evitando divergencias entre app y seed/CLI.
  - `scripts/ml_cli.py` pasó a reutilizar `resolve_db_path()` (se eliminó resolución duplicada local).
  - `seed_demo_data.py` dejó de apuntar por defecto a `./data/demo.db`; ahora delega resolución al bootstrap compartido y abre lecturas de conteo vía `bootstrap_database` para mantener logs homogéneos.
  - Se corrigió `SEED_DEMO.bat` para fijar `CLINICDESK_DB_PATH=%CD%\data\clinicdesk.db`, pasar `--sqlite-path` explícito y ejecutar con `--reset`.
  - Se añadió `START_APP.bat` para arrancar la app con la misma ruta oficial de DB.
  - Se añadió test de no regresión para `resolve_db_path()` cubriendo arg/env/default y validando default oficial.
- **Decisiones**:
  - Cambio mínimo orientado a observabilidad: mantener compatibilidad (`db_path()`) y centralizar solo la resolución de ruta + logs críticos.
  - Precedencia explícita `arg > env > default` para que scripts/batch puedan fijar ruta inequívoca en ejecución.
- **Qué queda**:
  - Si se desea, unificar también `launch.bat/launcher.bat` legacy para que redirijan internamente a `START_APP.bat`.

- **DATE/TIME**: 2026-02-28 12:40 UTC
- **Paso**: Paso 19: Seed completo + UX no-tech + progress dialogs
- **Qué se hizo**:
  - Se extendió `SeedDemoDataRequest`/`Response` para cubrir medicamentos, materiales, recetas, líneas, dispensaciones, movimientos, turnos y ausencias.
  - `DemoDataSeeder` ahora siembra inventario, recetas/líneas, dispensaciones, movimientos de farmacia/material, calendario por meses y ausencias, respetando FKs y orden de inserción.
  - Se añadieron argumentos CLI para `seed-demo`: `--meds`, `--materials`, `--recipes`, `--movements`, `--turns-months`, `--absences`.
  - Se corrigió desalineación de esquema con columnas requeridas por consultas/UI (`recetas.estado`, `receta_lineas.cantidad/pendiente/estado`, `movimientos*.referencia`) + migraciones idempotentes.
  - Se añadieron logs estructurados `screen_data_loaded module=X count=N db_path=...` en pantallas críticas para diagnóstico de módulos vacíos.
  - Se incorporó empty state con botón “Generar datos demo” en módulos de farmacia/recetas/medicamentos/materiales/dispensaciones.
  - Se agregó test core de no regresión para comprobar que tras seed las consultas clave devuelven filas > 0.

- **DATE/TIME**: 2026-02-28 13:40 UTC
- **Paso**: Paso 20: Analítica no técnica + progreso/cancel reutilizable
- **Qué se hizo**:
  - Se creó `AnalyticsWorkflowService` en application para orquestar flujo guiado (`prepare_analysis`, `train`, `score`, `drift`, `export_all`, `run_full_workflow`) sobre `DemoMLFacade`.
  - Se añadió `ProgressDialog` reutilizable con barra de progreso, pasos con estado, cancelación y mini-log filtrado por `run_id`.
  - Se actualizó `LogBufferHandler` para soportar snapshot compartido y filtro por `run_id`, habilitando trazabilidad de ejecución en UI.
  - Se rediseñó la pantalla como **Analítica (Demo)** con lenguaje no técnico, wizard de 4 pasos, botón **Ejecutar Demo Completa** y panel **Avanzado** colapsado por defecto.
  - Se incorporó persistencia de “Último análisis” por `QSettings` (`last_run_ts`, `last_export_dir`, `last_summary_text`, `last_internal_versions`).
  - Se añadieron tests core de workflow con fakes: resultado completo con exports, cancel token y drift opcional.
- **Decisiones**:
  - Orquestación de negocio en capa application, manteniendo UI como composición/presentación sin mezclar reglas de flujo.
  - Terminología orientada a negocio para reducir carga técnica en demos ejecutivas.
- **Riesgos**:
  - La validación visual del diálogo PySide6 sigue siendo manual (sin test UI automatizado en este paso).

- **DATE/TIME**: 2026-02-28 15:20 UTC
- **Paso**: Paso 21: UX polish + KPI exports para Power BI
- **Qué se hizo**:
  - Se mejoró **Analítica (Demo)** con copy no técnico en los 4 pasos, panel superior de KPI cards y actualización incremental tras preparar, entrenar, score y drift.
  - Se añadió widget reutilizable `KpiCard` con estados visuales (`ok/warn/bad`) sin dependencias externas.
  - Se incorporó semáforo de drift en capa application (`drift_explain.py`) con mensaje humano y umbrales `GREEN < 0.1`, `AMBER < 0.2`, `RED >= 0.2`.
  - Se agregó botón **Abrir carpeta de exportación** con soporte cross-platform (`os.startfile` en Windows, `open`/`xdg-open` en Unix) y manejo friendly de error.
  - Se implementó nuevo caso de uso `ExportKpisCSV` para generar `kpi_overview.csv`, `kpi_scores_by_bucket.csv`, `kpi_drift_by_feature.csv`, `kpi_training_metrics.csv`.
  - Se integró export KPI en `AnalyticsWorkflowService.export_all()` y en CLI con subcomando `export kpis`.
  - Se actualizaron README y contratos documentales para explicar uso en dashboard Power BI.
  - Se añadieron tests de core para explicación de drift y export KPI.
- **Decisiones**:
  - Se mantuvo la lógica de semaforización fuera de UI para cumplir separación Clean Architecture.
  - Se definieron contratos KPI estables en formato CSV para consumo directo por BI sin transformación adicional.
- **Riesgos**:
  - Captura automática de screenshot no aplica directamente a UI PySide6 desktop en este entorno headless.
- **Qué queda**:
  - Evaluar automatización futura de snapshots de UI desktop (por ejemplo con harness Qt) en CI.


- **DATE/TIME**: 2026-02-28 06:30 UTC
- **Paso**: Paso XX: Structural quality gate (LOC + CC + hotspots)
- **Qué se hizo**:
  - Se implementó `scripts/structural_gate.py` con análisis AST (LOC, CC por función/método, LOC por clase/función, score de hotspots por archivo).
  - Se integró el paso `STRUCTURAL_GATE` en `scripts/quality_gate.py` con modos `--strict` y `--report-only`, más `--thresholds` para configuración externa.
  - Se creó `scripts/quality_thresholds.json` con umbrales por defecto, exclusiones y allowlist configurable por ruta.
  - Se añadió generación obligatoria de `docs/quality_report.md` con resumen, violaciones por tipo, top hotspots y recomendaciones accionables.
  - Se añadieron pruebas unitarias en `tests/test_structural_gate.py` para CC, LOC, exclusiones y allowlist.
  - Se actualizó `docs/ci_quality_gate.md` para documentar métricas, umbrales y plan de reducción de deuda.
- **Decisiones**:
  - Se evitó dependencia externa (`radon/xenon`) para mantener reproducibilidad y tiempos de ejecución bajos.
  - Se mantuvo el gate de UI fuera del bloqueo estructural usando exclusiones explícitas.
- **Riesgos**:
  - La CC implementada es una aproximación AST; puede diferir de herramientas especializadas en casos límite.
- **Qué queda**:
  - Ajustar allowlist inicial con deuda real del repositorio y reducirla de forma incremental por sprint.

- **DATE/TIME**: 2026-02-28 10:35 UTC
- **Paso**: PR 1 — Bajar hotspots sin dolor
- **Qué se hizo**:
  - Se corrigieron exclusiones del structural gate para ignorar UI real (`clinicdesk/app/ui/**`, `clinicdesk/app/pages/**`) y se mantuvieron exclusiones de `tests/**`, `migrations/**` y `sql/**` en thresholds/defaults.
  - Se añadió allowlist temporal y acotada solo para `scripts/structural_gate.py` y `scripts/ml_cli.py` con justificación explícita de deuda técnica controlada.
  - Se dividió `csv_service` en módulos cohesivos (`csv_parsing`, `csv_mapping`, `csv_resolver`, `csv_errors`) dejando `CsvService` como orquestador fino y manteniendo API pública.
  - Se redujo CC de `read_csv` en `csv_io.py` extrayendo fases de headers/requeridos/normalización de filas.
  - Se redujo tamaño de `SeedDemoData.execute` con extracción de etapas de generación, persistencia y armado de respuesta sin alterar lógica de negocio.
  - Se regeneró `docs/quality_report.md` para reflejar el nuevo estado de violaciones/hotspots.
  - Métrica structural gate: antes `violations_count=38`, `blocking_violations_count=38`, `top_hotspots=10`; después `violations_count=21`, `blocking_violations_count=21`, `top_hotspots=9`.
- **Decisiones**:
  - No se allowlisteó ninguna ruta de application/domain/infrastructure para mantener pressure de mejora en core.
  - Se priorizó refactor de bajo riesgo con extracción de helpers/mixins puros y sin cambios de contratos de entrada/salida.
- **Riesgos**:
  - El structural gate estricto aún falla por hotspots/violaciones preexistentes fuera del alcance de este PR incremental.
- **Qué queda**:
  - Reducir CC/LOC en use cases de stock/dispensación/crear cita y repositorios SQLite grandes para cerrar el gate estricto completamente.
